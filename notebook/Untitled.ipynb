{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5388f1-5194-48ce-a798-6ed002ef216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TCG scraper at 2025-04-22 04:01:28.868643\n",
      "Scraping PTCG data...\n",
      "Launching browser for PTCG links: &vers%5B%5D=sv10, UR\n",
      "Attempt 1/3\n",
      "Attempt 1 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "Attempt 2/3\n",
      "Attempt 2 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "Attempt 3/3\n",
      "Attempt 3 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "All attempts to launch browser failed\n",
      "No links found for rarity UR\n",
      "Collected 0 PTCG links\n",
      "No PTCG data collected, skipping CSV save\n",
      "PTCG scraping completed: 0 rows\n",
      "Scraping OPCG data...\n",
      "Launching browser for OPCG links: , P-SEC\n",
      "Attempt 1/3\n",
      "Attempt 1 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "Attempt 2/3\n",
      "Attempt 2 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "Attempt 3/3\n",
      "Attempt 3 failed: BrowserType.launch: Executable doesn't exist at /Users/fm/Library/Caches/ms-playwright/chromium-1140/chrome-mac/Chromium.app/Contents/MacOS/Chromium\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║ Looks like Playwright was just installed or updated.       ║\n",
      "║ Please run the following command to download new browsers: ║\n",
      "║                                                            ║\n",
      "║     playwright install                                     ║\n",
      "║                                                            ║\n",
      "║ <3 Playwright Team                                         ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "All attempts to launch browser failed\n",
      "No links found for rarity P-SEC\n",
      "Collected 0 OPCG links\n",
      "No OPCG data collected, skipping CSV save\n",
      "OPCG scraping completed: 0 rows\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re, os\n",
    "from datetime import datetime\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "opcg_result_path = '../data/opcg'\n",
    "ptcg_result_path = '../data/ptcg'\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def extract_ptcg_rarity_and_card_name(content):\n",
    "    pattern = r'(?:S-TD|UR|AR|SR|SAR)\\s+[^\\s\\n]+'\n",
    "    match = re.search(pattern, content)\n",
    "    if match:\n",
    "        return match.group().split(' ')[0], match.group().split(' ')[1]\n",
    "    return None\n",
    "\n",
    "def extract_opcg_rarity_and_card_name(content):\n",
    "    pattern = r'(?:P-SEC|SEC|P-SR|P-R|P-L|SP|-)\\s+[^\\s\\n]+'\n",
    "    matches = re.search(pattern, content)\n",
    "    if matches:\n",
    "        matches = matches.group()\n",
    "        if matches.split(' ')[0] == '-':\n",
    "            return 'DON', matches.split(' ')[1]\n",
    "        return matches.split(' ')[0], matches.split(' ')[1]\n",
    "    return None\n",
    "\n",
    "def extract_ptcg_card_index(content):\n",
    "    pattern = r'\\d{3}/\\d{3}'\n",
    "    match = re.search(pattern, content)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return None\n",
    "\n",
    "def extract_opcg_card_index(content):\n",
    "    pattern = r'(?:OP|EB|ST)\\d{2}-\\d{3}'\n",
    "    match = re.search(pattern, content)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return None\n",
    "\n",
    "def extract_card_price(content):\n",
    "    pattern = r'\\d{1,3}(?:,\\d{3})* 円'\n",
    "    match = re.search(pattern, content)\n",
    "    if match:\n",
    "        price_str = match.group()\n",
    "        return int(price_str.replace(',', '').replace(' 円', ''))\n",
    "    return None\n",
    "\n",
    "async def extract_content(tcg_type, card_set, i):\n",
    "    print(f\"Extracting content for {tcg_type}/{card_set}/{i}\")\n",
    "    for attempt in range(3):\n",
    "        print(f\"Attempt {attempt+1}/3\")\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.chromium.launch(\n",
    "                    headless=True,\n",
    "                    args=['--no-sandbox', '--disable-gpu', '--disable-dev-shm-usage']\n",
    "                )\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(f'https://yuyu-tei.jp/sell/{tcg_type}/card/{card_set}/{i}', timeout=60000)\n",
    "                await page.wait_for_selector('.fw-bold', timeout=60000)\n",
    "                print(f\"Page loaded: https://yuyu-tei.jp/sell/{tcg_type}/card/{card_set}/{i}\")\n",
    "                fw_bold_texts = await page.evaluate('''() => {\n",
    "                    const boldElements = document.querySelectorAll('.fw-bold');\n",
    "                    return Array.from(boldElements).map(element => element.innerText).join('\\\\n');\n",
    "                }''')\n",
    "                return fw_bold_texts\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < 2:\n",
    "                await asyncio.sleep(5)\n",
    "            continue\n",
    "    print(\"All attempts to extract content failed\")\n",
    "    return None\n",
    "\n",
    "async def get_ptcg_links(vers, rarity):\n",
    "    print(f\"Launching browser for PTCG links: {vers}, {rarity}\")\n",
    "    for attempt in range(3):\n",
    "        print(f\"Attempt {attempt+1}/3\")\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.chromium.launch(\n",
    "                    headless=True,\n",
    "                    args=['--no-sandbox', '--disable-gpu', '--disable-dev-shm-usage']\n",
    "                )\n",
    "                page = await browser.new_page()\n",
    "                print(f'https://yuyu-tei.jp/sell/poc/s/search?search_word={vers}&rare={rarity}&type=&kizu=0')\n",
    "                await page.goto(f'https://yuyu-tei.jp/sell/poc/s/search?search_word={vers}&rare={rarity}&type=&kizu=0', timeout=60000)\n",
    "                hyperlinks = await page.evaluate('''() => {\n",
    "                    const links = document.querySelectorAll('a');\n",
    "                    return Array.from(links).map(link => link.href);\n",
    "                }''')\n",
    "                return hyperlinks\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < 2:\n",
    "                await asyncio.sleep(5)\n",
    "            continue\n",
    "    print(\"All attempts to launch browser failed\")\n",
    "    return []\n",
    "\n",
    "async def get_opcg_links(search_word, rarity):\n",
    "    print(f\"Launching browser for OPCG links: {search_word}, {rarity}\")\n",
    "    for attempt in range(3):\n",
    "        print(f\"Attempt {attempt+1}/3\")\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.chromium.launch(\n",
    "                    headless=True,\n",
    "                    args=['--no-sandbox', '--disable-gpu', '--disable-dev-shm-usage']\n",
    "                )\n",
    "                page = await browser.new_page()\n",
    "                print(f'https://yuyu-tei.jp/sell/opc/s/search?search_word={search_word}&rare={rarity}&type=&kizu=0')\n",
    "                await page.goto(f'https://yuyu-tei.jp/sell/opc/s/search?search_word={search_word}&rare={rarity}&type=&kizu=0', timeout=60000)\n",
    "                hyperlinks = await page.evaluate('''() => {\n",
    "                    const links = document.querySelectorAll('a');\n",
    "                    return Array.from(links).map(link => link.href);\n",
    "                }''')\n",
    "                return hyperlinks\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < 2:\n",
    "                await asyncio.sleep(5)\n",
    "            continue\n",
    "    print(\"All attempts to launch browser failed\")\n",
    "    return []\n",
    "\n",
    "async def scrape_ptcg():\n",
    "    ptcg_rarity_table = {\n",
    "        'UR': ['sv10']\n",
    "    }\n",
    "\n",
    "    links = []\n",
    "    for rarity in ptcg_rarity_table.keys():\n",
    "        vers = ''.join('&vers%5B%5D=' + i for i in ptcg_rarity_table[rarity])\n",
    "        all_links = await get_ptcg_links(vers, rarity)\n",
    "        if all_links:\n",
    "            cleaned_links = [url for url in all_links if any(val in url for val in ptcg_rarity_table[rarity]) and 'card' in url]\n",
    "            links += cleaned_links\n",
    "        else:\n",
    "            print(f\"No links found for rarity {rarity}\")\n",
    "\n",
    "    links = list(set(links))\n",
    "    sorted_links = sorted(links, key=lambda x: (x.split('/card/')[1].split('/')[0], int(x.split('/')[-1])))\n",
    "    print(f\"Collected {len(links)} PTCG links\")\n",
    "\n",
    "    pkm_df = pd.DataFrame(columns=['card_set', 'card_rarity', 'card_name', 'card_index', 'card_price', 'created_time'])\n",
    "    \n",
    "    for idx, link in enumerate(sorted_links, 1):\n",
    "        tcg_type = link.split('/')[-4]\n",
    "        card_set = link.split('/')[-2]\n",
    "        i = link.split('/')[-1]\n",
    "        print(f'Processing {idx}/{len(sorted_links)}')\n",
    "        content = await extract_content(tcg_type, card_set, i)\n",
    "        if content:\n",
    "            try:\n",
    "                card_rarity, card_name = extract_ptcg_rarity_and_card_name(content)\n",
    "            except:\n",
    "                print(f\"Failed to extract rarity/name for {link}\")\n",
    "                continue\n",
    "            card_index = extract_ptcg_card_index(content)\n",
    "            card_price = extract_card_price(content)\n",
    "            created_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pkm_df.loc[len(pkm_df)] = [card_set, card_rarity, card_name, card_index, card_price, created_time]\n",
    "\n",
    "    os.makedirs(ptcg_result_path, exist_ok=True)\n",
    "    \n",
    "    if pkm_df.empty:\n",
    "        print(\"No PTCG data collected, skipping CSV save\")\n",
    "        return pkm_df\n",
    "    \n",
    "    csv_path = f'{ptcg_result_path}/{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "    print(f\"Saving PTCG data to {csv_path}\")\n",
    "    pkm_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved {len(pkm_df)} rows to {csv_path}\")\n",
    "    return pkm_df\n",
    "\n",
    "async def scrape_opcg():\n",
    "    rarities = ['P-SEC']\n",
    "\n",
    "    links = []\n",
    "    for rarity in rarities:\n",
    "        search_word = 'スーパーパラレル' if rarity == '-' else ''\n",
    "        all_links = await get_opcg_links(search_word, rarity)\n",
    "        if all_links:\n",
    "            links += all_links\n",
    "        else:\n",
    "            print(f\"No links found for rarity {rarity}\")\n",
    "    \n",
    "    links = list(set(sorted([l for l in links if 'card' in l])))\n",
    "    sorted_links = sorted(links, key=lambda x: (x.split('/card/')[1].split('/')[0], int(x.split('/')[-1])))\n",
    "    print(f\"Collected {len(links)} OPCG links\")\n",
    "\n",
    "    op_df = pd.DataFrame(columns=['card_set', 'card_rarity', 'card_name', 'card_index', 'card_price', 'created_time'])\n",
    "\n",
    "    for idx, link in enumerate(sorted_links, 1):\n",
    "        tcg_type = link.split('/')[-4]\n",
    "        card_set = link.split('/')[-2]\n",
    "        i = link.split('/')[-1]\n",
    "        print(f'Processing {idx}/{len(sorted_links)}')\n",
    "        content = await extract_content(tcg_type, card_set, i)\n",
    "        if content:\n",
    "            try:\n",
    "                card_rarity, card_name = extract_opcg_rarity_and_card_name(content)\n",
    "            except:\n",
    "                print(f\"Failed to extract rarity/name for {link}\")\n",
    "                continue\n",
    "            card_index = extract_opcg_card_index(content)\n",
    "            card_price = extract_card_price(content)\n",
    "            created_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            op_df.loc[len(op_df)] = [card_set, card_rarity, card_name, card_index, card_price, created_time]\n",
    "\n",
    "    os.makedirs(opcg_result_path, exist_ok=True)\n",
    "    \n",
    "    if op_df.empty:\n",
    "        print(\"No OPCG data collected, skipping CSV save\")\n",
    "        return op_df\n",
    "    \n",
    "    csv_path = f'{opcg_result_path}/{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "    print(f\"Saving OPCG data to {csv_path}\")\n",
    "    op_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved {len(op_df)} rows to {csv_path}\")\n",
    "    return op_df\n",
    "\n",
    "async def main():\n",
    "    print(f\"Starting TCG scraper at {datetime.now()}\")\n",
    "    print(\"Scraping PTCG data...\")\n",
    "    ptcg_df = await scrape_ptcg()\n",
    "    print(f\"PTCG scraping completed: {len(ptcg_df)} rows\")\n",
    "    print(\"Scraping OPCG data...\")\n",
    "    opcg_df = await scrape_opcg()\n",
    "    print(f\"OPCG scraping completed: {len(opcg_df)} rows\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782db297-cd7f-4e24-86ab-455e12c76d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playwright\n",
      "  Downloading playwright-1.48.0-py3-none-macosx_11_0_universal2.whl.metadata (3.5 kB)\n",
      "Collecting greenlet==3.1.1 (from playwright)\n",
      "  Downloading greenlet-3.1.1-cp38-cp38-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting pyee==12.0.0 (from playwright)\n",
      "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/tcgview/lib/python3.8/site-packages (from pyee==12.0.0->playwright) (4.12.2)\n",
      "Downloading playwright-1.48.0-py3-none-macosx_11_0_universal2.whl (35.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp38-cp38-macosx_11_0_universal2.whl (271 kB)\n",
      "Downloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pyee, greenlet, playwright\n",
      "  Attempting uninstall: pyee\n",
      "    Found existing installation: pyee 11.1.1\n",
      "    Uninstalling pyee-11.1.1:\n",
      "      Successfully uninstalled pyee-11.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 2.0.0 requires pyee<12.0.0,>=11.0.0, but you have pyee 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed greenlet-3.1.1 playwright-1.48.0 pyee-12.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playwright\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
